{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from itertools import repeat\n",
    "from pipe import select\n",
    "from lark import Lark, Tree\n",
    "from box import Box\n",
    "import difflib\n",
    "import asyncio\n",
    "\n",
    "from api.kg import Query, execute_query, queries, actions, from_camel, to_camel\n",
    "from api.events import Event, emit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Pipeline:\n",
    "    spec: str\n",
    "    tree: Tree\n",
    "\n",
    "\n",
    "lower = lambda ll: [l.lower() for l in ll]\n",
    "approx_match = lambda token, options: difflib.get_close_matches(token.lower(), lower(options), n=3, cutoff=0.2)\n",
    "exact_match = lambda token, options: token if token.lower() in lower(options) else False\n",
    "cleanup = lambda obj, key: [[el['label'] if isinstance(el, dict) else el for el in path[key]] for path in obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(spec: str) -> Pipeline:\n",
    "    grammar = '''\n",
    "    DIGIT: \"0\"..\"9\"\n",
    "    INT: DIGIT+\n",
    "    FLOAT: INT? \".\" DIGIT+\n",
    "    NUMBER: FLOAT | INT\n",
    "    WORD: /[a-zA-Z_]+/\n",
    "    STRING: /\"[^\"]*\"/\n",
    "    start: expression (\">\" expression)*\n",
    "    key: WORD\n",
    "    value: WORD | NUMBER | STRING\n",
    "    kwarg: key \"=\" value\n",
    "    attribute: WORD\n",
    "    callable: attribute \"(\" kwarg? (\",\" kwarg)* \")\"\n",
    "    expression: attribute | callable\n",
    "\n",
    "    // imports from terminal library\n",
    "    // %import common.WORD\n",
    "    %import common.WS\n",
    "    %ignore WS\n",
    "    '''\n",
    "\n",
    "    l = Lark(grammar)\n",
    "    tree = l.parse(spec)\n",
    "    return Pipeline(spec, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def debug(pipeline: Pipeline) -> None:\n",
    "    emit(Event('DebuggingInitiated', {'pipeline': pipeline.spec}))\n",
    "\n",
    "    state = Box({\n",
    "        'pipeline': {\n",
    "            'steps': list(pipeline.tree.find_data('attribute') | select(lambda attr: attr.children[0].value)),\n",
    "        },\n",
    "        'tasks': list((await execute_query(queries['get tasks']))[0].get('nodes', []) | select(lambda n: from_camel(n['label']))),\n",
    "    })\n",
    "    \n",
    "    emit(Event('OperatorsExtracted', {'operators': list(state.pipeline.steps)}))\n",
    "\n",
    "    to_check, tasks = [], []\n",
    "    for step in state.pipeline.steps:\n",
    "        # TODO: try to find the exact match first\n",
    "        # TODO: feedback loop to confirm match\n",
    "        matches = approx_match(step, state.tasks)\n",
    "        operator = matches[0]\n",
    "        paths = cleanup((await execute_query(queries['get pathways'](operator, 'data_science_task'))), 'path')\n",
    "        paths = [l.split(':') for l in set(\":\".join(el) for el in paths)]\n",
    "        if paths:\n",
    "            emit(Event('TaskRecognized', {'task': step, 'paths': paths}))\n",
    "            tasks.append(operator)\n",
    "            to_check.extend(paths)\n",
    "    \n",
    "    emit(Event('TasksIdentified', {'tasks': tasks}))\n",
    "\n",
    "    actions_to_check = []\n",
    "    for task in tasks:\n",
    "        risks = cleanup((await execute_query(queries['get pathways'](task, 'risk'))), 'path')\n",
    "        if risks:\n",
    "            emit(Event('RisksIdentified', {'task': task, 'risks': risks}))\n",
    "            for risk in risks:\n",
    "                actions_to_check.extend(zip(repeat(task), risk[::2][1:-1]))\n",
    "\n",
    "    for task, risk in actions_to_check:\n",
    "        candidates = (await execute_query(Query(f\"\"\"MATCH p=(s)-[:`might mitigate`]->(:`{risk}`) RETURN s;\"\"\")))\n",
    "        candidates = [s['s']['label'] for s in candidates]\n",
    "        if candidates:\n",
    "            emit(Event('MitigationActionsIdentified', {'task': task, 'risk': risk, 'actions': candidates}))\n",
    "            for candidate in candidates:\n",
    "                alternatives = cleanup(await execute_query(actions[candidate](task)), 'connected_nodes')\n",
    "                emit(Event('SuggestionRendered', {'task': task, 'risk': risk, 'action': candidate, 'actions': alternatives}))\n",
    "\n",
    "\n",
    "async def main():\n",
    "    return await debug(pipeline('DataLoading(path=\"data/test.csv\") > TrainTestSplit(test_size=.2, random_state=42) > MinMaxScaler > OneHotEncoder > SVM'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = 'DataLoading(path=\"data/test.csv\") > TrainTestSplit(test_size=.2, random_state=42) > MinMaxScaler > OneHotEncoder > SVM'\n",
    "p = pipeline(spec=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tree(Token('RULE', 'start'), [Tree(Token('RULE', 'expression'), [Tree(Token('RULE', 'callable'), [Tree(Token('RULE', 'attribute'), [Token('WORD', 'DataLoading')]), Tree(Token('RULE', 'kwarg'), [Tree(Token('RULE', 'key'), [Token('WORD', 'path')]), Tree(Token('RULE', 'value'), [Token('STRING', '\"data/test.csv\"')])])])]), Tree(Token('RULE', 'expression'), [Tree(Token('RULE', 'callable'), [Tree(Token('RULE', 'attribute'), [Token('WORD', 'TrainTestSplit')]), Tree(Token('RULE', 'kwarg'), [Tree(Token('RULE', 'key'), [Token('WORD', 'test_size')]), Tree(Token('RULE', 'value'), [Token('NUMBER', '.2')])]), Tree(Token('RULE', 'kwarg'), [Tree(Token('RULE', 'key'), [Token('WORD', 'random_state')]), Tree(Token('RULE', 'value'), [Token('NUMBER', '42')])])])]), Tree(Token('RULE', 'expression'), [Tree(Token('RULE', 'attribute'), [Token('WORD', 'MinMaxScaler')])]), Tree(Token('RULE', 'expression'), [Tree(Token('RULE', 'attribute'), [Token('WORD', 'OneHotEncoder')])]), Tree(Token('RULE', 'expression'), [Tree(Token('RULE', 'attribute'), [Token('WORD', 'SVM')])])])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = Box({\n",
    "        'pipeline': {\n",
    "            'steps': list(p.tree.find_data('attribute') | select(lambda attr: attr.children[0].value)),\n",
    "        },\n",
    "        'tasks': list((await execute_query(queries['get tasks']))[0].get('nodes', []) | select(lambda n: from_camel(n['label']))),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
